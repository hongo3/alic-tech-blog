#!/usr/bin/env python3
"""
æ—¢å­˜ã®è¨˜äº‹ã‚’æ‰‹å‹•ã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æœ€æ–°5è¨˜äº‹ã®ã¿ã‚’ä¿æŒã—ã€index.htmlã‚‚æ›´æ–°
"""

from pathlib import Path
import shutil
from datetime import datetime, timezone, timedelta
import re
import subprocess

# æ—¥æœ¬æ¨™æº–æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = timezone(timedelta(hours=9))

def get_jst_now():
    """ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—"""
    return datetime.now(JST)

def cleanup_articles(keep_count=5):
    """è¨˜äº‹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦æœ€æ–°Nä»¶ã®ã¿ã‚’ä¿æŒ"""
    posts_dir = Path("posts")
    docs_articles_dir = Path("docs/articles")
    
    if not posts_dir.exists():
        print("âŒ posts directory not found")
        return
    
    # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
    all_md_files = list(posts_dir.glob("*.md"))
    print(f"\nğŸ“Š ç¾åœ¨ã®è¨˜äº‹æ•°: {len(all_md_files)}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    sorted_files = sorted(all_md_files, key=lambda x: x.name, reverse=True)
    
    # ä¿æŒã™ã‚‹è¨˜äº‹ã¨å‰Šé™¤ã™ã‚‹è¨˜äº‹ã‚’åˆ†ã‘ã‚‹
    keep_files = sorted_files[:keep_count]
    delete_files = sorted_files[keep_count:]
    
    print(f"\nâœ… ä¿æŒã™ã‚‹è¨˜äº‹: {len(keep_files)}ä»¶")
    for f in keep_files[:5]:  # æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º
        print(f"   - {f.name}")
    
    if delete_files:
        print(f"\nğŸ—‘ï¸  å‰Šé™¤ã™ã‚‹è¨˜äº‹: {len(delete_files)}ä»¶")
        print(f"   æœ€ã‚‚å¤ã„è¨˜äº‹: {delete_files[-1].name}")
        print(f"   æœ€ã‚‚æ–°ã—ã„å‰Šé™¤å¯¾è±¡: {delete_files[0].name}")
        
        # ç¢ºèª
        response = input(f"\nâš ï¸  {len(delete_files)}ä»¶ã®è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if response.lower() != 'y':
            print("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        # å‰Šé™¤å®Ÿè¡Œ
        for md_file in delete_files:
            md_file.unlink()
            
            # å¯¾å¿œã™ã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
            html_file = docs_articles_dir / f"{md_file.stem}.html"
            if html_file.exists():
                html_file.unlink()
        
        print(f"âœ… {len(delete_files)}ä»¶ã®è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
    else:
        print("\nâœ… å‰Šé™¤å¯¾è±¡ã®è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“")

def rebuild_html():
    """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆ"""
    print("\nğŸ“„ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆä¸­...")
    
    # convert_articles.pyã‚’å®Ÿè¡Œ
    result = subprocess.run(['python', 'convert_articles.py'], capture_output=True, text=True)
    if result.stdout:
        print(result.stdout)
    if result.stderr:
        print("ã‚¨ãƒ©ãƒ¼:", result.stderr)

def update_index_html():
    """index.htmlã‚’æ›´æ–°ã—ã¦æœ€æ–°5è¨˜äº‹ã®ã¿ã‚’è¡¨ç¤º"""
    print("\nğŸ“ index.htmlã‚’æ›´æ–°ä¸­...")
    
    posts_dir = Path("posts")
    index_path = Path("docs/index.html")
    
    if not index_path.exists():
        print("âŒ index.html not found")
        return
    
    # æœ€æ–°5ä»¶ã®è¨˜äº‹ã‚’å–å¾—
    md_files = sorted(posts_dir.glob("*.md"), key=lambda x: x.name, reverse=True)[:5]
    
    # å„è¨˜äº‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    articles_html = []
    for i, md_file in enumerate(md_files):
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        meta_dict = {}
        if content.startswith('---'):
            # ç‰¹æ®Šãªå½¢å¼ã®å‡¦ç†ï¼ˆ---\n...ã®å ´åˆï¼‰
            content = content.replace('---\\n', '---\n')
            parts = content.split('---', 2)
            if len(parts) >= 3:
                metadata = parts[1].strip()
                for line in metadata.split('\n'):
                    if ':' in line:
                        key, value = line.split(':', 1)
                        meta_dict[key.strip()] = value.strip()
        
        # æ—¥ä»˜ã«JSTã‚’è¿½åŠ 
        date_str = meta_dict.get('date', '')
        if date_str and 'JST' not in date_str:
            date_str += ' JST'
        
        # NEWãƒãƒƒã‚¸ã¯æœ€æ–°è¨˜äº‹ã®ã¿
        new_badge = '<span class="new-badge">NEW</span>' if i == 0 else ''
        
        article_html = f'''
            <article class="article">
                <h2>{meta_dict.get('title', 'Untitled')}{new_badge}</h2>
                <p class="meta">
                    ğŸ“… {date_str} | 
                    ğŸ·ï¸ {meta_dict.get('tags', '')} | 
                    ğŸ”— <a href="{meta_dict.get('source', '#')}" target="_blank">å‚è€ƒå…ƒ</a>
                </p>
                <div class="preview">{meta_dict.get('title', '')}ã«ã¤ã„ã¦ã€æœ€æ–°ã®æŠ€è¡“å‹•å‘ã¨å®Ÿè£…æ–¹æ³•ã‚’è§£èª¬ã—ã¾ã™ã€‚</div>
                <a href="articles/{md_file.stem}.html" class="read-more">
                    ç¶šãã‚’èª­ã‚€ â†’
                </a>
            </article>'''
        
        articles_html.append(article_html)
    
    # index.htmlã‚’èª­ã¿è¾¼ã‚€
    with open(index_path, 'r', encoding='utf-8') as f:
        html = f.read()
    
    # è¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°
    articles_section = f'<section id="articles">{"".join(articles_html)}\n        </section>'
    html = re.sub(r'<section id="articles">.*?</section>', articles_section, html, flags=re.DOTALL)
    
    # æ›´æ–°æ™‚åˆ»ã‚’å¤‰æ›´
    jst_now = get_jst_now()
    html = re.sub(
        r'æœ€çµ‚æ›´æ–°: [0-9:]+( JST)?',
        f'æœ€çµ‚æ›´æ–°: {jst_now.strftime("%H:%M:%S")} JST',
        html
    )
    
    # ä¿å­˜
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print("âœ… index.htmlã‚’æ›´æ–°ã—ã¾ã—ãŸ")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ§¹ è¨˜äº‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    jst_now = get_jst_now()
    print(f"â° ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
    cleanup_articles(keep_count=5)
    
    # HTMLã‚’å†ç”Ÿæˆ
    rebuild_html()
    
    # index.htmlã‚’æ›´æ–°
    update_index_html()
    
    print("\nâœ¨ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†!")

if __name__ == "__main__":
    main()