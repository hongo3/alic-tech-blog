#!/usr/bin/env python3
"""
è‡ªå·±è©•ä¾¡ãƒ»æ”¹å–„æ©Ÿèƒ½ä»˜ãè¨˜äº‹ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å‰å›ã®è¨˜äº‹ã‚’è©•ä¾¡ã—ã€ãƒ«ãƒ¼ãƒ«ã‚’æ›´æ–°ã—ã¦ã‹ã‚‰æ–°ã—ã„è¨˜äº‹ã‚’ç”Ÿæˆã™ã‚‹
"""

import asyncio
from datetime import datetime, timezone, timedelta
from pathlib import Path
import json
import time
import os
import random
import re
import subprocess
from article_evaluator import SelfImprovingBlogSystem, ArticleEvaluator

# æ—¥æœ¬æ¨™æº–æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = timezone(timedelta(hours=9))

def get_jst_now():
    """ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—"""
    return datetime.now(JST)

class ImprovedArticleGenerator:
    """æ”¹å–„ã•ã‚ŒãŸè¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.evaluation_system = SelfImprovingBlogSystem()
        self.rules_file = Path("BLOG_WRITING_RULES.md")
        self.current_rules = self._load_current_rules()
        self.improvement_suggestions = []
        
    def _load_current_rules(self) -> str:
        """ç¾åœ¨ã®ãƒ«ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if self.rules_file.exists():
            with open(self.rules_file, "r", encoding="utf-8") as f:
                return f.read()
        return ""
    
    async def generate_with_evaluation(self):
        """è©•ä¾¡ã‚’å«ã‚ãŸè¨˜äº‹ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹"""
        
        print("ğŸ”„ STEP 1: æ—¢å­˜è¨˜äº‹ã®è©•ä¾¡ã¨æ”¹å–„ææ¡ˆã®ç”Ÿæˆ")
        print("-" * 50)
        
        # è©•ä¾¡ã¨æ”¹å–„ã‚’å®Ÿè¡Œ
        improvement_report = await self.evaluation_system.evaluate_and_improve()
        
        # æ”¹å–„ææ¡ˆã‚’æŠ½å‡º
        if improvement_report["recent_evaluations"]:
            latest_eval = improvement_report["recent_evaluations"][0]
            self.improvement_suggestions = latest_eval.get("improvement_suggestions", [])
            
            print(f"ğŸ“Š æœ€æ–°è¨˜äº‹ã®è©•ä¾¡ã‚¹ã‚³ã‚¢: {latest_eval['total_score']:.1f}/100")
            
            if latest_eval.get("weaknesses"):
                print("\nâš ï¸  æ¤œå‡ºã•ã‚ŒãŸå¼±ç‚¹:")
                for weakness in latest_eval["weaknesses"]:
                    print(f"  - {weakness}")
            
            if self.improvement_suggestions:
                print("\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
                for suggestion in self.improvement_suggestions:
                    print(f"  - {suggestion}")
        
        # ãƒ«ãƒ¼ãƒ«ãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã¯å†èª­ã¿è¾¼ã¿
        if improvement_report["rules_updated"]:
            print("\nğŸ“ ãƒ«ãƒ¼ãƒ«ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸï¼")
            self.current_rules = self._load_current_rules()
        
        print("\nğŸ”„ STEP 2: æ”¹å–„ã‚’åæ˜ ã—ãŸæ–°è¨˜äº‹ã®ç”Ÿæˆ")
        print("-" * 50)
        
        # æ”¹å–„ã‚’åæ˜ ã—ãŸè¨˜äº‹ã‚’ç”Ÿæˆ
        article_data = await self._generate_improved_article()
        
        print("\nâœ… è¨˜äº‹ç”Ÿæˆå®Œäº†ï¼")
        
        return article_data
    
    async def _generate_improved_article(self):
        """æ”¹å–„ææ¡ˆã‚’åæ˜ ã—ãŸè¨˜äº‹ã‚’ç”Ÿæˆ"""
        
        # ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ï¼‰
        topic_data = self._select_balanced_topic()
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã‚¿ã‚°ã®å®šç¾©ï¼ˆgenerate_article_v3.pyã‹ã‚‰ï¼‰
        CATEGORIES = {
            "ai_development": {
                "name": "AIé–‹ç™º",
                "tags": ["AI", "æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "é–‹ç™º"],
                "color": "#667eea"
            },
            "web_tech": {
                "name": "WebæŠ€è¡“",
                "tags": ["Web", "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰", "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰", "API"],
                "color": "#48bb78"
            },
            "infrastructure": {
                "name": "ã‚¤ãƒ³ãƒ•ãƒ©",
                "tags": ["ã‚¯ãƒ©ã‚¦ãƒ‰", "DevOps", "ã‚¤ãƒ³ãƒ•ãƒ©", "è‡ªå‹•åŒ–"],
                "color": "#ed8936"
            },
            "security": {
                "name": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
                "tags": ["ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼", "èªè¨¼", "æš—å·åŒ–"],
                "color": "#e53e3e"
            },
            "data_science": {
                "name": "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹",
                "tags": ["ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿", "çµ±è¨ˆ", "å¯è¦–åŒ–"],
                "color": "#38b2ac"
            }
        }
        
        # è¨˜äº‹å†…å®¹ã‚’ç”Ÿæˆï¼ˆæ”¹å–„ææ¡ˆã‚’è€ƒæ…®ï¼‰
        content = self._generate_content_with_improvements(topic_data, CATEGORIES)
        
        # è¨˜äº‹ã‚’ä¿å­˜
        jst_now = get_jst_now()
        article_id = f"article_{int(jst_now.timestamp())}"
        category = CATEGORIES[topic_data["category"]]
        
        posts_dir = Path("posts")
        posts_dir.mkdir(exist_ok=True)
        
        article_path = posts_dir / f"{article_id}.md"
        with open(article_path, "w", encoding="utf-8") as f:
            f.write(f"---\n")
            f.write(f"title: {topic_data['title']}\n")
            f.write(f"date: {jst_now.strftime('%Y-%m-%d %H:%M')}\n")
            f.write(f"category: {category['name']}\n")
            f.write(f"tags: {', '.join(category['tags'])}\n")
            f.write(f"difficulty: {topic_data['difficulty']}\n")
            f.write(f"reading_time: {topic_data['reading_time']}\n")
            f.write(f"evaluation_aware: true\n")
            f.write(f"---\n\n")
            f.write(content)
        
        print(f"âœ… ç”Ÿæˆè¨˜äº‹: {topic_data['title']}")
        print(f"   ã‚«ãƒ†ã‚´ãƒªãƒ¼: {category['name']}")
        print(f"   æ”¹å–„åæ˜ : {len(self.improvement_suggestions)}é …ç›®")
        
        # ç”Ÿæˆã—ãŸè¨˜äº‹ã‚’å³åº§ã«è©•ä¾¡
        print("\nğŸ”„ STEP 3: ç”Ÿæˆè¨˜äº‹ã®å³æ™‚è©•ä¾¡")
        print("-" * 50)
        
        evaluator = ArticleEvaluator()
        new_evaluation = await evaluator.evaluate_article(article_path)
        
        print(f"ğŸ“Š æ–°è¨˜äº‹ã®ã‚¹ã‚³ã‚¢:")
        print(f"  - æŠ€è¡“çš„æ­£ç¢ºæ€§: {new_evaluation['scores']['technical_accuracy']:.1f}/25")
        print(f"  - èª­ã¿ã‚„ã™ã•: {new_evaluation['scores']['readability']:.1f}/25")
        print(f"  - å®Ÿç”¨æ€§: {new_evaluation['scores']['practicality']:.1f}/25")
        print(f"  - ç‹¬è‡ªæ€§: {new_evaluation['scores']['originality']:.1f}/25")
        print(f"  - ç·åˆã‚¹ã‚³ã‚¢: {new_evaluation['total_score']:.1f}/100")
        
        # HTMLã«å¤‰æ›
        self._convert_to_html()
        
        # index.htmlã‚’æ›´æ–°
        self._update_index_html()
        
        # å¤ã„è¨˜äº‹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self._cleanup_old_articles()
        
        return {
            "article_data": topic_data,
            "evaluation": new_evaluation,
            "improvements_applied": self.improvement_suggestions
        }
    
    def _select_balanced_topic(self):
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ"""
        
        # æœ€è¿‘ã®è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†å¸ƒã‚’åˆ†æ
        posts_dir = Path("posts")
        recent_articles = sorted(
            posts_dir.glob("*.md"), 
            key=lambda x: x.stat().st_mtime, 
            reverse=True
        )[:10]
        
        category_counts = {}
        for article in recent_articles:
            with open(article, "r", encoding="utf-8") as f:
                content = f.read()
                if content.startswith("---"):
                    metadata = content.split("---")[1]
                    for line in metadata.split("\n"):
                        if line.startswith("category:"):
                            category = line.split(":", 1)[1].strip()
                            category_counts[category] = category_counts.get(category, 0) + 1
        
        # ä½¿ç”¨é »åº¦ã®ä½ã„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å„ªå…ˆ
        TOPICS = [
            {
                "title": "ã€2025å¹´æœ€æ–°ã€‘AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¤‰ãˆã‚‹é–‹ç™ºç¾å ´ - AutoGenã¨LangChainã®å®Ÿè·µæ¯”è¼ƒ",
                "short_title": "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€æ–°å‹•å‘",
                "category": "ai_development",
                "source_url": "https://github.com/microsoft/autogen",
                "reference_sites": [
                    "https://qiita.com/",
                    "https://zenn.dev/",
                    "https://b.hatena.ne.jp/hotentry/it"
                ],
                "keywords": ["AutoGen", "LangChain", "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "è‡ªå¾‹å‹AI"],
                "difficulty": "ä¸­ç´š",
                "reading_time": "20åˆ†"
            },
            {
                "title": "Next.js 15å®Œå…¨æ”»ç•¥:App RouterÃ—Server ComponentsÃ—Streamingã§ä½œã‚‹çˆ†é€ŸWebã‚¢ãƒ—ãƒª",
                "short_title": "Next.js 15ã®æ–°æ©Ÿèƒ½è§£èª¬",
                "category": "web_tech",
                "source_url": "https://github.com/vercel/next.js",
                "reference_sites": [
                    "https://nextjs.org/blog",
                    "https://vercel.com/blog",
                    "https://dev.to/t/nextjs"
                ],
                "keywords": ["Next.js", "React", "Server Components", "App Router"],
                "difficulty": "ä¸­ç´š",
                "reading_time": "25åˆ†"
            },
            {
                "title": "KubernetesÃ—GitOpså®Ÿè·µ:ArgoCDã¨Fluxã§å®Ÿç¾ã™ã‚‹å®Œå…¨è‡ªå‹•åŒ–ã‚¤ãƒ³ãƒ•ãƒ©",
                "short_title": "K8s GitOpså®Ÿè·µã‚¬ã‚¤ãƒ‰",
                "category": "infrastructure",
                "source_url": "https://github.com/argoproj/argo-cd",
                "reference_sites": [
                    "https://kubernetes.io/blog/",
                    "https://www.cncf.io/blog/",
                    "https://itnext.io/"
                ],
                "keywords": ["Kubernetes", "GitOps", "ArgoCD", "Flux", "CI/CD"],
                "difficulty": "ä¸Šç´š",
                "reading_time": "35åˆ†"
            },
            {
                "title": "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®Ÿè£…ã‚¬ã‚¤ãƒ‰:BeyondCorpãƒ¢ãƒ‡ãƒ«ã§ä½œã‚‹æ¬¡ä¸–ä»£èªè¨¼åŸºç›¤",
                "short_title": "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å…¥é–€",
                "category": "security",
                "source_url": "https://github.com/pomerium/pomerium",
                "reference_sites": [
                    "https://www.csoonline.com/",
                    "https://www.darkreading.com/",
                    "https://thehackernews.com/"
                ],
                "keywords": ["ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆ", "BeyondCorp", "èªè¨¼", "ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡"],
                "difficulty": "ä¸Šç´š",
                "reading_time": "30åˆ†"
            },
            {
                "title": "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æ–°å¸¸è­˜:Apache Spark vs Databricks vs Snowflakeå¾¹åº•æ¯”è¼ƒ",
                "short_title": "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†åŸºç›¤ã®é¸ã³æ–¹",
                "category": "data_science",
                "source_url": "https://github.com/apache/spark",
                "reference_sites": [
                    "https://databricks.com/blog",
                    "https://www.snowflake.com/blog/",
                    "https://towardsdatascience.com/"
                ],
                "keywords": ["Spark", "Databricks", "Snowflake", "ETL", "ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¯"],
                "difficulty": "ä¸­ç´š",
                "reading_time": "30åˆ†"
            }
        ]
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
        category_map = {
            "AIé–‹ç™º": "ai_development",
            "WebæŠ€è¡“": "web_tech",
            "ã‚¤ãƒ³ãƒ•ãƒ©": "infrastructure",
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£": "security",
            "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹": "data_science"
        }
        
        # æœ€ã‚‚ä½¿ç”¨é »åº¦ã®ä½ã„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ
        min_count = float('inf')
        preferred_category = None
        
        for cat_name, cat_key in category_map.items():
            count = category_counts.get(cat_name, 0)
            if count < min_count:
                min_count = count
                preferred_category = cat_key
        
        # å„ªå…ˆã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ
        preferred_topics = [t for t in TOPICS if t["category"] == preferred_category]
        if preferred_topics:
            return random.choice(preferred_topics)
        
        # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ 
        return random.choice(TOPICS)
    
    def _generate_content_with_improvements(self, topic_data, CATEGORIES):
        """æ”¹å–„ææ¡ˆã‚’åæ˜ ã—ãŸè¨˜äº‹å†…å®¹ã‚’ç”Ÿæˆ"""
        
        # generate_article_v3.pyã®generate_detailed_contenté–¢æ•°ã®å†…å®¹ã‚’
        # æ”¹å–„ææ¡ˆã«åŸºã¥ã„ã¦ä¿®æ­£
        
        # åŸºæœ¬çš„ãªå†…å®¹ç”Ÿæˆï¼ˆv3ã‹ã‚‰ï¼‰
        from generate_article_v3 import generate_ai_thought_process
        
        title = topic_data["title"]
        short_title = topic_data["short_title"]
        keywords = topic_data["keywords"]
        category = CATEGORIES[topic_data["category"]]
        difficulty = topic_data["difficulty"]
        reading_time = topic_data["reading_time"]
        
        # AIã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ç”Ÿæˆ
        thought_process = generate_ai_thought_process(topic_data)
        
        # æ”¹å–„ææ¡ˆã‚’åæ˜ 
        content_adjustments = {
            "extra_code_examples": False,
            "more_detailed_explanations": False,
            "better_structure": False,
            "ai_perspective": False
        }
        
        for suggestion in self.improvement_suggestions:
            if "ã‚³ãƒ¼ãƒ‰ä¾‹" in suggestion:
                content_adjustments["extra_code_examples"] = True
            if "è©³ç´°" in suggestion or "èª¬æ˜" in suggestion:
                content_adjustments["more_detailed_explanations"] = True
            if "æ§‹é€ " in suggestion or "ã‚»ã‚¯ã‚·ãƒ§ãƒ³" in suggestion:
                content_adjustments["better_structure"] = True
            if "AI" in suggestion:
                content_adjustments["ai_perspective"] = True
        
        # æ”¹å–„ã‚’åæ˜ ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
        content = self._build_improved_content(
            topic_data, 
            thought_process, 
            content_adjustments
        )
        
        return content
    
    def _build_improved_content(self, topic_data, thought_process, adjustments):
        """æ”¹å–„ã‚’åæ˜ ã—ãŸè¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰"""
        
        # ã“ã“ã§å®Ÿéš›ã®æ”¹å–„ã‚’åæ˜ ã—ãŸè¨˜äº‹ã‚’ç”Ÿæˆ
        # ï¼ˆgenerate_article_v3.pyã®å†…å®¹ã‚’åŸºã«ã€æ”¹å–„ææ¡ˆã‚’åæ˜ ï¼‰
        
        # ç°¡ç•¥åŒ–ã®ãŸã‚ã€v3ã®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã—
        from generate_article_v3 import generate_detailed_content
        
        # åŸºæœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
        base_content = generate_detailed_content(topic_data)
        
        # æ”¹å–„ã‚’é©ç”¨
        if adjustments["extra_code_examples"]:
            # ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’è¿½åŠ 
            base_content = base_content.replace(
                "## ğŸ’¡ å®Ÿè·µçš„ãªå¿œç”¨ä¾‹",
                "## ğŸ’¡ å®Ÿè·µçš„ãªå¿œç”¨ä¾‹\n\n### è¿½åŠ ã®å®Ÿè£…ä¾‹ï¼ˆè©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãï¼‰\n\n" +
                self._generate_extra_code_example(topic_data) +
                "\n\n## ğŸ’¡ å®Ÿè·µçš„ãªå¿œç”¨ä¾‹"
            )
        
        if adjustments["more_detailed_explanations"]:
            # ã‚ˆã‚Šè©³ç´°ãªèª¬æ˜ã‚’è¿½åŠ 
            base_content = base_content.replace(
                "ã“ã‚Œã‚‰ã®çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§",
                "ã“ã‚Œã‚‰ã®çŸ¥è­˜ã‚’æ·±ãç†è§£ã—ã€å®Ÿè·µã§æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå…·ä½“çš„ãªæˆæœãŒæœŸå¾…ã§ãã¾ã™ï¼š\n\n" +
                "1. **é–‹ç™ºåŠ¹ç‡ã®å‘ä¸Š**: é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¸æŠã«ã‚ˆã‚Šã€é–‹ç™ºæ™‚é–“ã‚’30-50%çŸ­ç¸®\n" +
                "2. **å“è³ªã®å‘ä¸Š**: ä½“ç³»çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€ãƒã‚°ã®ç™ºç”Ÿç‡ã‚’å¤§å¹…ã«å‰Šæ¸›\n" +
                "3. **ãƒãƒ¼ãƒ ç”Ÿç”£æ€§**: æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ã‚ˆã‚Šã€ãƒãƒ¼ãƒ å…¨ä½“ã®ç”Ÿç”£æ€§ãŒå‘ä¸Š\n\n" +
                "ã“ã‚Œã‚‰ã®çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§"
            )
        
        return base_content
    
    def _generate_extra_code_example(self, topic_data):
        """è¿½åŠ ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ç”Ÿæˆ"""
        return f"""
```python
# {topic_data['keywords'][0]}ã®å®Ÿè·µçš„ãªä½¿ç”¨ä¾‹
class ImprovedImplementation:
    \"\"\"è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãæ”¹å–„ã•ã‚ŒãŸå®Ÿè£…\"\"\"
    
    def __init__(self):
        self.config = self._load_optimized_config()
        self.error_handler = ErrorHandler()
        
    async def process_with_monitoring(self, data):
        \"\"\"
        ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ä»˜ãã®å‡¦ç†
        
        æ”¹å–„ç‚¹:
        - ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†
        - è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
        \"\"\"
        try:
            # å‡¦ç†æ™‚é–“ã‚’è¨ˆæ¸¬
            start_time = time.time()
            
            # ãƒ¡ã‚¤ãƒ³å‡¦ç†
            result = await self._main_process(data)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²
            processing_time = time.time() - start_time
            await self._record_metrics({
                'processing_time': processing_time,
                'data_size': len(data),
                'success': True
            })
            
            return result
            
        except Exception as e:
            # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¨˜éŒ²
            await self.error_handler.handle(e, context={
                'data_sample': data[:100],
                'timestamp': datetime.now().isoformat()
            })
            
            # è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
            if self._should_retry(e):
                return await self._retry_with_backoff(data)
            
            raise
```"""
    
    def _convert_to_html(self):
        """HTMLã«å¤‰æ›"""
        if Path("convert_articles_v3.py").exists():
            print("ğŸ“ HTMLã«å¤‰æ›ä¸­...")
            result = subprocess.run(
                ["python", "convert_articles_v3.py"], 
                capture_output=True, 
                text=True
            )
            if result.returncode != 0:
                print(f"âŒ HTMLå¤‰æ›ã‚¨ãƒ©ãƒ¼: {result.stderr}")
            else:
                print("âœ… HTMLå¤‰æ›å®Œäº†")
    
    def _update_index_html(self):
        """index.htmlã‚’æ›´æ–°"""
        if Path("update_to_modern_ui_v3.py").exists():
            print("ğŸ“ index.htmlã‚’æ›´æ–°ä¸­...")
            subprocess.run(["python", "update_to_modern_ui_v3.py"])
    
    def _cleanup_old_articles(self, keep_count=5):
        """å¤ã„è¨˜äº‹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print(f"\nğŸ§¹ è¨˜äº‹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæœ€æ–°{keep_count}ä»¶ã‚’ä¿æŒï¼‰")
        
        posts_dir = Path("posts")
        if not posts_dir.exists():
            return
        
        md_files = sorted(posts_dir.glob("*.md"), key=lambda x: x.stat().st_mtime, reverse=True)
        
        if len(md_files) <= keep_count:
            print(f"  ç¾åœ¨ã®è¨˜äº‹æ•°: {len(md_files)}ä»¶ - ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦")
            return
        
        files_to_delete = md_files[keep_count:]
        print(f"  å‰Šé™¤å¯¾è±¡: {len(files_to_delete)}ä»¶ã®å¤ã„è¨˜äº‹")
        
        for md_file in files_to_delete:
            print(f"  ğŸ—‘ï¸  å‰Šé™¤: {md_file.name}")
            md_file.unlink()
            
            html_file = Path("docs/articles") / f"{md_file.stem}.html"
            if html_file.exists():
                html_file.unlink()

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¤– è‡ªå·±è©•ä¾¡ãƒ»æ”¹å–„å‹è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  v1.0")
    print("=" * 60)
    
    jst_now = get_jst_now()
    print(f"â° ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
    
    # æ”¹å–„å‹è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    generator = ImprovedArticleGenerator()
    
    # è©•ä¾¡ã¨æ”¹å–„ã‚’å«ã‚ãŸè¨˜äº‹ç”Ÿæˆã‚’å®Ÿè¡Œ
    result = await generator.generate_with_evaluation()
    
    print("\n" + "=" * 60)
    print("âœ… è‡ªå·±æ”¹å–„ãƒ«ãƒ¼ãƒ—å®Œäº†ï¼")
    print(f"  - ç”Ÿæˆè¨˜äº‹: {result['article_data']['title'][:40]}...")
    print(f"  - è©•ä¾¡ã‚¹ã‚³ã‚¢: {result['evaluation']['total_score']:.1f}/100")
    print(f"  - é©ç”¨æ”¹å–„æ•°: {len(result['improvements_applied'])}é …ç›®")
    
    # æ”¹å–„ã®åŠ¹æœã‚’è¡¨ç¤º
    if result['improvements_applied']:
        print("\nğŸ“ˆ é©ç”¨ã•ã‚ŒãŸæ”¹å–„:")
        for improvement in result['improvements_applied']:
            print(f"  âœ“ {improvement}")

if __name__ == "__main__":
    asyncio.run(main())