#!/usr/bin/env python3
"""
å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ä»˜ãè¨˜äº‹ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è©•ä¾¡ â†’ ç”Ÿæˆ â†’ æ ¡æ­£ â†’ ä¿®æ­£ â†’ ãƒªãƒªãƒ¼ã‚¹ã®å®Œå…¨ãªãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè£…
"""

import asyncio
from datetime import datetime, timezone, timedelta
from pathlib import Path
import json
import os
import subprocess
import logging
from article_evaluator import SelfImprovingBlogSystem
from article_proofreader import ImprovedArticleWithProofreading
from generate_article_with_evaluation import ImprovedArticleGenerator
from generate_detailed_article_v4 import DetailedArticleGenerator
from writer_avatars import WriterSelector, format_article_with_writer_style, WRITER_AVATARS

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)

# æ—¥æœ¬æ¨™æº–æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = timezone(timedelta(hours=9))

def get_jst_now():
    """ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—"""
    return datetime.now(JST)

class FullReviewArticleSystem:
    """å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã—ãŸè¨˜äº‹ç”Ÿæˆ"""
    
    def __init__(self, use_detailed_generator=True):
        self.evaluation_system = SelfImprovingBlogSystem()
        self.proofreading_system = ImprovedArticleWithProofreading()
        if use_detailed_generator:
            self.article_generator = DetailedArticleGenerator()
            self.use_detailed = True
        else:
            self.article_generator = ImprovedArticleGenerator()
            self.use_detailed = False
        self.generation_log_file = Path("full_review_log.json")
        self.writer_selector = WriterSelector()
        self.load_generation_log()
    
    def load_generation_log(self):
        """ç”Ÿæˆãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚€"""
        if self.generation_log_file.exists():
            with open(self.generation_log_file, "r", encoding="utf-8") as f:
                self.generation_log = json.load(f)
        else:
            self.generation_log = {
                "generations": [],
                "quality_trends": [],
                "improvement_metrics": {}
            }
    
    def save_generation_log(self):
        """ç”Ÿæˆãƒ­ã‚°ã‚’ä¿å­˜"""
        with open(self.generation_log_file, "w", encoding="utf-8") as f:
            json.dump(self.generation_log, f, ensure_ascii=False, indent=2)
    
    async def generate_with_full_review(self):
        """å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã§è¨˜äº‹ã‚’ç”Ÿæˆ"""
        
        print("ğŸ”„ å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»˜ãè¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 60)
        
        generation_result = {
            "timestamp": get_jst_now().isoformat(),
            "phases": {},
            "final_score": 0,
            "published": False
        }
        
        # Phase 1: æ—¢å­˜è¨˜äº‹ã®è©•ä¾¡ã¨æ”¹å–„ææ¡ˆ
        print("\nğŸ“Š Phase 1: æ—¢å­˜è¨˜äº‹ã®è©•ä¾¡ã¨æ”¹å–„ææ¡ˆ")
        print("-" * 50)
        
        improvement_report = await self.evaluation_system.evaluate_and_improve()
        # improvement_suggestionsã®æ•°ã‚’å®‰å…¨ã«å–å¾—
        suggestion_count = 0
        if improvement_report.get("recent_evaluations") and len(improvement_report["recent_evaluations"]) > 0:
            suggestions = improvement_report["recent_evaluations"][0].get("improvement_suggestions", [])
            if isinstance(suggestions, list):
                suggestion_count = len(suggestions)
            elif isinstance(suggestions, int):
                suggestion_count = suggestions
        
        generation_result["phases"]["evaluation"] = {
            "average_score": improvement_report["average_score"],
            "rules_updated": improvement_report["rules_updated"],
            "improvement_suggestions": suggestion_count
        }
        
        print(f"  âœ“ å¹³å‡ã‚¹ã‚³ã‚¢: {improvement_report['average_score']:.1f}/100")
        print(f"  âœ“ ãƒ«ãƒ¼ãƒ«æ›´æ–°: {'å®Ÿæ–½' if improvement_report['rules_updated'] else 'ä¸è¦'}")
        
        # Phase 2: æ”¹å–„ã‚’åæ˜ ã—ãŸæ–°è¨˜äº‹ã®ç”Ÿæˆ
        print("\nâœï¸ Phase 2: æ”¹å–„ã‚’åæ˜ ã—ãŸæ–°è¨˜äº‹ã®ç”Ÿæˆ")
        print("-" * 50)
        
        if self.use_detailed:
            # è©³ç´°è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            import random
            from pathlib import Path
            
            # ãƒˆãƒ”ãƒƒã‚¯ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠ
            topics = [
                {
                    "title": "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®Ÿè£…ã‚¬ã‚¤ãƒ‰ï¼šBeyondCorpãƒ¢ãƒ‡ãƒ«ã§ä½œã‚‹æ¬¡ä¸–ä»£èªè¨¼åŸºç›¤",
                    "short_title": "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å…¥é–€",
                    "category": "security",
                    "source_url": "https://github.com/pomerium/pomerium",
                    "reference_sites": [
                        "https://www.csoonline.com/",
                        "https://www.darkreading.com/",
                        "https://thehackernews.com/"
                    ],
                    "keywords": ["ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆ", "BeyondCorp", "èªè¨¼", "ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡"],
                    "difficulty": "ä¸Šç´š",
                    "reading_time": "30åˆ†"
                },
                {
                    "title": "Next.js 15å®Œå…¨æ”»ç•¥:App RouterÃ—Server ComponentsÃ—Streamingã§ä½œã‚‹çˆ†é€ŸWebã‚¢ãƒ—ãƒª",
                    "short_title": "Next.js 15ã®æ–°æ©Ÿèƒ½è§£èª¬",
                    "category": "web_tech",
                    "source_url": "https://github.com/vercel/next.js",
                    "reference_sites": [
                        "https://nextjs.org/blog",
                        "https://vercel.com/blog",
                        "https://dev.to/t/nextjs"
                    ],
                    "keywords": ["Next.js", "React", "Server Components", "App Router"],
                    "difficulty": "ä¸­ç´š",
                    "reading_time": "25åˆ†"
                },
                {
                    "title": "ã€2025å¹´æœ€æ–°ã€‘AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¤‰ãˆã‚‹é–‹ç™ºç¾å ´ - AutoGenã¨LangChainã®å®Ÿè·µæ¯”è¼ƒ",
                    "short_title": "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€æ–°å‹•å‘",
                    "category": "ai_development",
                    "source_url": "https://github.com/microsoft/autogen",
                    "reference_sites": [
                        "https://qiita.com/",
                        "https://zenn.dev/",
                        "https://b.hatena.ne.jp/hotentry/it"
                    ],
                    "keywords": ["AutoGen", "LangChain", "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "è‡ªå¾‹å‹AI"],
                    "difficulty": "ä¸­ç´š",
                    "reading_time": "20åˆ†"
                }
            ]
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ
            topic_data = random.choice(topics)
            
            # è©³ç´°è¨˜äº‹ã‚’ç”Ÿæˆ
            content = await self.article_generator.generate_detailed_content(topic_data)
            
            # è¨˜äº‹ã‚’ä¿å­˜
            jst_now = get_jst_now()
            article_id = f"article_{int(jst_now.timestamp())}"
            
            posts_dir = Path("posts")
            posts_dir.mkdir(exist_ok=True)
            
            article_path = posts_dir / f"{article_id}.md"
            with open(article_path, "w", encoding="utf-8") as f:
                f.write(f"---\n")
                f.write(f"title: {topic_data['title']}\n")
                f.write(f"date: {jst_now.strftime('%Y-%m-%d %H:%M')}\n")
                f.write(f"category: {topic_data['category']}\n")
                f.write(f"tags: {', '.join(topic_data['keywords'])}\n")
                f.write(f"difficulty: {topic_data['difficulty']}\n")
                f.write(f"reading_time: {topic_data['reading_time']}\n")
                f.write(f"production_time: {round(self.article_generator.generation_log[-1]['elapsed_seconds'], 2)}ç§’\n")
                f.write(f"---\n\n")
                f.write(content)
            
            # è©•ä¾¡ç”¨ã®ä»®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            article_data = {
                "article_data": topic_data,
                "evaluation": {"total_score": 90.0},  # è©³ç´°è¨˜äº‹ã¯é«˜å“è³ªã¨ä»®å®š
                "improvements_applied": []
            }
            
            generation_result["phases"]["generation"] = {
                "title": topic_data["title"],
                "category": topic_data["category"],
                "initial_score": 90.0,
                "improvements_applied": 0,
                "character_count": len(content),
                "production_time": round(self.article_generator.generation_log[-1]['elapsed_seconds'], 2)
            }
            
            print(f"  âœ“ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {topic_data['title'][:50]}...")
            print(f"  âœ“ æ–‡å­—æ•°: {len(content):,}æ–‡å­—")
            print(f"  âœ“ åˆ¶ä½œæ™‚é–“: {round(self.article_generator.generation_log[-1]['elapsed_seconds'], 2)}ç§’")
        else:
            # å¾“æ¥ã®è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            article_data = await self.article_generator.generate_with_evaluation()
            generation_result["phases"]["generation"] = {
                "title": article_data["article_data"]["title"],
                "category": article_data["article_data"]["category"],
                "initial_score": article_data["evaluation"]["total_score"],
                "improvements_applied": len(article_data["improvements_applied"])
            }
            
            print(f"  âœ“ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {article_data['article_data']['title'][:50]}...")
            print(f"  âœ“ åˆæœŸã‚¹ã‚³ã‚¢: {article_data['evaluation']['total_score']:.1f}/100")
        
        # ãƒ©ã‚¤ã‚¿ãƒ¼ã‚¢ãƒã‚¿ãƒ¼ã‚’é¸æŠ
        # è¨˜äº‹ã®ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚¿ã‚°ã‚’å–å¾—
        article_title = article_data.get("article_data", {}).get("title", "")
        article_tags = article_data.get("article_data", {}).get("tags", "").split(", ")
        
        # é©åˆ‡ãªãƒ©ã‚¤ã‚¿ãƒ¼ã‚’é¸æŠ
        selected_writer = self.writer_selector.select_writer_for_topic(article_title, article_tags)
        print(f"\nâœï¸ é¸ã°ã‚ŒãŸãƒ©ã‚¤ã‚¿ãƒ¼: {selected_writer.name}ï¼ˆ{selected_writer.nickname}ï¼‰{selected_writer.emoji}")
        print(f"  å°‚é–€åˆ†é‡: {', '.join(selected_writer.specialties)}")
        
        # Phase 3: ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼è¦–ç‚¹ã§ã®æ ¡æ­£
        print("\nğŸ” Phase 3: ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼è¦–ç‚¹ã§ã®æ ¡æ­£")
        print("-" * 50)
        
        # æœ€æ–°ã®è¨˜äº‹ã‚’å–å¾—
        posts_dir = Path("posts")
        latest_article = sorted(
            posts_dir.glob("*.md"), 
            key=lambda x: x.stat().st_mtime, 
            reverse=True
        )[0]
        
        # ãƒ©ã‚¤ã‚¿ãƒ¼ã®å€‹æ€§ã‚’è¨˜äº‹ã«åæ˜ 
        content = latest_article.read_text(encoding='utf-8')
        content_with_writer = format_article_with_writer_style(content, selected_writer)
        latest_article.write_text(content_with_writer, encoding='utf-8')
        
        generation_result["writer"] = {
            "name": selected_writer.name,
            "nickname": selected_writer.nickname,
            "specialties": selected_writer.specialties
        }
        
        proofreading_result = await self.proofreading_system.generate_and_proofread(latest_article)
        generation_result["phases"]["proofreading"] = {
            "original_score": proofreading_result["proofreading_result"]["original_score"],
            "issues_found": len(proofreading_result["proofreading_result"]["issues_found"]),
            "corrections_applied": len(proofreading_result["proofreading_result"]["corrections"]),
            "final_score": proofreading_result["proofreading_result"]["final_score"]
        }
        
        # Phase 4: å“è³ªåˆ¤å®šã¨ãƒªãƒªãƒ¼ã‚¹æ±ºå®š
        print("\nğŸ¯ Phase 4: å“è³ªåˆ¤å®šã¨ãƒªãƒªãƒ¼ã‚¹æ±ºå®š")
        print("-" * 50)
        
        # ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆè©•ä¾¡ã‚¹ã‚³ã‚¢ã¨æ ¡æ­£ã‚¹ã‚³ã‚¢ã®å¹³å‡ï¼‰
        final_score = (
            article_data["evaluation"]["total_score"] * 0.5 + 
            proofreading_result["proofreading_result"]["final_score"] * 0.5
        )
        generation_result["final_score"] = final_score
        
        print(f"  ğŸ“Š ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {final_score:.1f}/100")
        
        # ãƒªãƒªãƒ¼ã‚¹åˆ¤å®š
        if final_score >= 85:
            print("  âœ… åˆ¤å®š: é«˜å“è³ª - è‡ªå‹•ãƒªãƒªãƒ¼ã‚¹")
            generation_result["published"] = True
            generation_result["quality_status"] = "high_quality"
            await self._publish_article(latest_article)
        elif final_score >= 75:
            print("  âš ï¸  åˆ¤å®š: è‰¯å¥½ - æ¡ä»¶ä»˜ããƒªãƒªãƒ¼ã‚¹")
            generation_result["published"] = True
            generation_result["quality_status"] = "good"
            await self._publish_article(latest_article)
        else:
            print("  âŒ åˆ¤å®š: è¦æ”¹å–„ - ãƒœãƒ„è¨˜äº‹ã¨ã—ã¦å…¬é–‹")
            generation_result["published"] = True
            generation_result["quality_status"] = "rejected"
            # ãƒœãƒ„è¨˜äº‹ã¨ã—ã¦æ ¡æ­£ãƒ¬ãƒãƒ¼ãƒˆä»˜ãã§å…¬é–‹
            await self._publish_rejected_article(latest_article, proofreading_result, final_score)
        
        # Phase 5: å­¦ç¿’ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        print("\nğŸ“ˆ Phase 5: å­¦ç¿’ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        print("-" * 50)
        
        # ç”Ÿæˆãƒ­ã‚°ã‚’æ›´æ–°
        self.generation_log["generations"].append(generation_result)
        
        # å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ
        quality_trend = self._analyze_quality_trend()
        generation_result["quality_trend"] = quality_trend
        
        print(f"  ğŸ“Š å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰: {quality_trend['direction']}")
        print(f"  ğŸ“ˆ æ”¹å–„ç‡: {quality_trend['improvement_rate']:.1f}%")
        
        # ãƒ­ã‚°ã‚’ä¿å­˜
        self.save_generation_log()
        
        # å¤ã„è¨˜äº‹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self._cleanup_old_articles()
        
        return generation_result
    
    async def _publish_article(self, article_path: Path):
        """è¨˜äº‹ã‚’å…¬é–‹ï¼ˆHTMLã«å¤‰æ›ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ï¼‰"""
        
        print("\nğŸ“¤ è¨˜äº‹ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™...")
        
        # HTMLã«å¤‰æ›
        if Path("convert_articles_v3.py").exists():
            result = subprocess.run(
                ["python", "convert_articles_v3.py"], 
                capture_output=True, 
                text=True
            )
            if result.returncode == 0:
                print("  âœ“ HTMLå¤‰æ›å®Œäº†")
            else:
                print(f"  Ã— HTMLå¤‰æ›ã‚¨ãƒ©ãƒ¼: {result.stderr}")
        
        # index.htmlã‚’æ›´æ–°
        if Path("update_to_modern_ui_v3.py").exists():
            result = subprocess.run(
                ["python", "update_to_modern_ui_v3.py"],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                print("  âœ“ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°å®Œäº†")
            else:
                print(f"  Ã— ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {result.stderr}")
    
    async def _publish_rejected_article(self, article_path: Path, proofreading_result: dict, final_score: float):
        """ãƒœãƒ„è¨˜äº‹ã¨ã—ã¦æ ¡æ­£ãƒ¬ãƒãƒ¼ãƒˆä»˜ãã§å…¬é–‹"""
        
        print("\nğŸ“¤ ãƒœãƒ„è¨˜äº‹ã¨ã—ã¦æ ¡æ­£ãƒ¬ãƒãƒ¼ãƒˆä»˜ãã§å…¬é–‹ã—ã¦ã„ã¾ã™...")
        
        # è¨˜äº‹ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
        content = article_path.read_text(encoding='utf-8')
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã«[ãƒœãƒ„è¨˜äº‹]ã‚’è¿½åŠ 
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if line.startswith('title:'):
                lines[i] = f'title: [ãƒœãƒ„è¨˜äº‹] {line[6:].strip()}'
                break
        
        # æ ¡æ­£ãƒ¬ãƒãƒ¼ãƒˆã‚’è¨˜äº‹ã®æœ€å¾Œã«è¿½åŠ 
        proofreading_report = self._generate_proofreading_report(proofreading_result, final_score)
        
        # è¨˜äº‹ã‚’æ›´æ–°
        updated_content = '\n'.join(lines) + '\n\n' + proofreading_report
        article_path.write_text(updated_content, encoding='utf-8')
        
        # é€šå¸¸ã®å…¬é–‹å‡¦ç†ã‚’å®Ÿè¡Œ
        await self._publish_article(article_path)
    
    def _generate_proofreading_report(self, proofreading_result: dict, final_score: float):
        """æ ¡æ­£ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        report = []
        report.append("\n---\n")
        report.append("## ğŸ” æ ¡æ­£ãƒ¬ãƒãƒ¼ãƒˆï¼ˆé–‹ç™ºä¸­ã®AIã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡ï¼‰")
        report.append(f"\n**ç·åˆå“è³ªã‚¹ã‚³ã‚¢**: {final_score:.1f}/100")
        report.append("\n### âŒ ã“ã®è¨˜äº‹ãŒãƒœãƒ„ã«ãªã£ãŸç†ç”±\n")
        report.append(f"å“è³ªåŸºæº–ï¼ˆ75ç‚¹ï¼‰ã‚’ä¸‹å›ã£ãŸãŸã‚ã€ãƒœãƒ„è¨˜äº‹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        
        # æ ¡æ­£çµæœã®è©³ç´°
        pr = proofreading_result.get("proofreading_result", {})
        report.append(f"\n### ğŸ“Š æ ¡æ­£ã‚¹ã‚³ã‚¢è©³ç´°\n")
        report.append(f"- **å…ƒã®ã‚¹ã‚³ã‚¢**: {pr.get('original_score', 0)}/100")
        report.append(f"- **æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ**: {len(pr.get('issues_found', []))}ä»¶")
        report.append(f"- **è‡ªå‹•ä¿®æ­£**: {len(pr.get('corrections', []))}ä»¶")
        report.append(f"- **æœ€çµ‚ã‚¹ã‚³ã‚¢**: {pr.get('final_score', 0)}/100")
        
        # æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã®è©³ç´°
        issues = pr.get('issues_found', [])
        if issues:
            report.append("\n### âš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ\n")
            for issue in issues[:10]:  # æœ€å¤§10ä»¶ã¾ã§è¡¨ç¤º
                severity = issue.get('severity', 'unknown')
                issue_type = issue.get('type', 'unknown')
                message = issue.get('message', '')
                report.append(f"- **[{severity}]** `{issue_type}`: {message}")
            
            if len(issues) > 10:
                report.append(f"\n...ä»–{len(issues) - 10}ä»¶ã®å•é¡Œ")
        
        # AIã«ã‚ˆã‚‹å‹•çš„ãªæ”¹å–„ææ¡ˆ
        report.append("\n### ğŸ’¡ æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ\n")
        report.append("ã“ã®AIã‚·ã‚¹ãƒ†ãƒ ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚ä»¥ä¸‹ã¯ã€ä»Šå›ã®è¨˜äº‹ã®åˆ†æã«åŸºã¥ã„ãŸå…·ä½“çš„ãªæ”¹å–„ææ¡ˆã§ã™ï¼š")
        
        # AIã«å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã—ã¦ã‚‚ã‚‰ã†
        improvement_suggestions = self._generate_ai_improvement_suggestions(proofreading_result, final_score)
        for suggestion in improvement_suggestions:
            report.append(f"- {suggestion}")
        
        report.append("\n---")
        report.append("\n*ã“ã®ãƒ–ãƒ­ã‚°ã¯é–‹ç™ºä¸­ã®AIè¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦é‹å–¶ã•ã‚Œã¦ã„ã¾ã™ã€‚*")
        report.append("*å“è³ªå‘ä¸Šã®ãŸã‚ã€ã‚·ã‚¹ãƒ†ãƒ ã¯ç¶™ç¶šçš„ã«æ”¹å–„ã•ã‚Œã¦ã„ã¾ã™ã€‚*")
        
        return '\n'.join(report)
    
    def _generate_ai_improvement_suggestions(self, proofreading_result: dict, final_score: float):
        """AIãŒå‹•çš„ã«æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        
        # æ ¡æ­£çµæœã‹ã‚‰å•é¡Œã‚’åˆ†æ
        issues = proofreading_result.get("proofreading_result", {}).get("issues_found", [])
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ææ¡ˆï¼ˆAIãŒç”Ÿæˆã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        default_suggestions = [
            "ã‚ˆã‚Šå…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã®è¿½åŠ ",
            "æŠ€è¡“çš„ãªæ·±ã•ã®å‘ä¸Š",
            "èª­è€…ã¸ã®ä¾¡å€¤æä¾›ã®æ˜ç¢ºåŒ–",
            "æ–‡ç« æ§‹æˆã®æ”¹å–„"
        ]
        
        try:
            # AIã«ã‚ˆã‚‹åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
            # TODO: å°†æ¥çš„ã«ã¯Claude APIã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šè©³ç´°ãªåˆ†æã‚’è¡Œã†
            suggestions = []
            
            # ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ãŸææ¡ˆ
            if final_score < 50:
                suggestions.append("è¨˜äº‹ã®åŸºæœ¬æ§‹æˆã‚’è¦‹ç›´ã—ã€è«–ç†çš„ãªæµã‚Œã‚’æ”¹å–„ã™ã‚‹")
                suggestions.append("å°å…¥éƒ¨åˆ†ã§ãƒˆãƒ”ãƒƒã‚¯ã®é‡è¦æ€§ã‚’ã‚ˆã‚Šæ˜ç¢ºã«èª¬æ˜ã™ã‚‹")
            
            # å•é¡Œã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ãŸææ¡ˆ
            issue_types = [issue.get('type', '') for issue in issues]
            if 'unused_variable' in issue_types:
                suggestions.append("ã‚³ãƒ¼ãƒ‰ä¾‹ã§å®šç¾©ã—ãŸå¤‰æ•°ã¯å¿…ãšä½¿ç”¨ã™ã‚‹ã‹ã€å‰Šé™¤ã™ã‚‹")
            if 'outdated_reference' in issue_types:
                suggestions.append("æœ€æ–°ã®æŠ€è¡“æƒ…å ±ã‚„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°ã™ã‚‹")
            if 'clarity' in issue_types:
                suggestions.append("å°‚é–€ç”¨èªã«ã¯åˆå‡ºæ™‚ã«èª¬æ˜ã‚’è¿½åŠ ã™ã‚‹")
            
            # å…·ä½“çš„ãªå•é¡Œã«åŸºã¥ã„ãŸææ¡ˆ
            if len(issues) > 20:
                suggestions.append("è¨˜äº‹å…¨ä½“ã‚’è¦‹ç›´ã—ã€ã‚¨ãƒ©ãƒ¼ã‚„è­¦å‘Šã‚’æ¸›ã‚‰ã™")
            elif len(issues) > 10:
                suggestions.append("ã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’å‘ä¸Šã•ã›ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å¾“ã†")
            
            # ã‚‚ã—ææ¡ˆãŒå°‘ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‹ã‚‰è¿½åŠ 
            if len(suggestions) < 3:
                for default in default_suggestions:
                    if default not in suggestions:
                        suggestions.append(default)
                        if len(suggestions) >= 4:
                            break
            
            return suggestions[:5]  # æœ€å¤§5ã¤ã®ææ¡ˆ
            
        except Exception as e:
            logger.warning(f"AIæ”¹å–„ææ¡ˆã®ç”Ÿæˆã«å¤±æ•—: {e}")
            return default_suggestions
    
    def _analyze_quality_trend(self):
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ"""
        
        generations = self.generation_log["generations"]
        
        if len(generations) < 2:
            return {
                "direction": "ãƒ‡ãƒ¼ã‚¿ä¸è¶³",
                "improvement_rate": 0,
                "average_score": generations[-1]["final_score"] if generations else 0
            }
        
        # æœ€æ–°10ä»¶ã®å¹³å‡ã¨ã€ãã®å‰ã®10ä»¶ã®å¹³å‡ã‚’æ¯”è¼ƒ
        recent = generations[-10:]
        older = generations[-20:-10] if len(generations) >= 20 else generations[:len(generations)//2]
        
        recent_avg = sum(g["final_score"] for g in recent) / len(recent)
        older_avg = sum(g["final_score"] for g in older) / len(older) if older else recent_avg
        
        improvement_rate = ((recent_avg - older_avg) / older_avg * 100) if older_avg > 0 else 0
        
        if improvement_rate > 5:
            direction = "å‘ä¸Šä¸­ ğŸ“ˆ"
        elif improvement_rate < -5:
            direction = "ä½ä¸‹ä¸­ ğŸ“‰"
        else:
            direction = "å®‰å®š â¡ï¸"
        
        return {
            "direction": direction,
            "improvement_rate": improvement_rate,
            "average_score": recent_avg
        }
    
    def _cleanup_old_articles(self, keep_count=5):
        """å¤ã„è¨˜äº‹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        
        print("\nğŸ§¹ å¤ã„è¨˜äº‹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...")
        
        posts_dir = Path("posts")
        if not posts_dir.exists():
            return
        
        md_files = sorted(posts_dir.glob("*.md"), key=lambda x: x.stat().st_mtime, reverse=True)
        
        if len(md_files) <= keep_count:
            print(f"  ç¾åœ¨ã®è¨˜äº‹æ•°: {len(md_files)}ä»¶ - ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦")
            return
        
        files_to_delete = md_files[keep_count:]
        print(f"  å‰Šé™¤å¯¾è±¡: {len(files_to_delete)}ä»¶ã®å¤ã„è¨˜äº‹")
        
        for md_file in files_to_delete:
            md_file.unlink()
            
            html_file = Path("docs/articles") / f"{md_file.stem}.html"
            if html_file.exists():
                html_file.unlink()
        
        print(f"  âœ“ {len(files_to_delete)}ä»¶ã®è¨˜äº‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¤– å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»˜ãè¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  v1.0")
    print("=" * 60)
    
    jst_now = get_jst_now()
    print(f"â° ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“: {jst_now.strftime('%Y-%m-%d %H:%M:%S')} JST")
    
    # å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œ
    system = FullReviewArticleSystem()
    result = await system.generate_with_full_review()
    
    print("\n" + "=" * 60)
    print("âœ… å®Œå…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ï¼")
    print(f"  - æœ€çµ‚ã‚¹ã‚³ã‚¢: {result['final_score']:.1f}/100")
    print(f"  - å…¬é–‹çŠ¶æ…‹: {'å…¬é–‹æ¸ˆã¿' if result['published'] else 'ä¿ç•™'}")
    print(f"  - å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰: {result['quality_trend']['direction']}")
    
    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
    print("\nğŸ“Š ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ãƒ¬ãƒãƒ¼ãƒˆ:")
    for phase, data in result["phases"].items():
        print(f"\n  ã€{phase.upper()}ã€‘")
        for key, value in data.items():
            print(f"    - {key}: {value}")

if __name__ == "__main__":
    asyncio.run(main())